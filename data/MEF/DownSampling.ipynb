{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (236285, 19089)\n",
      "Num of unique days = 39\n"
     ]
    }
   ],
   "source": [
    "import scanpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "days_df = pd.read_csv(\"raw/cell_days.txt\", index_col='id', sep='\\t')\n",
    "adata = scanpy.read_h5ad(\"raw/ExprMatrix.h5ad\") # cell x gene\n",
    "adata.obs = adata.obs.join(days_df)\n",
    "\n",
    "adata = adata[~pd.isna(adata.obs['day']), :]\n",
    "meta_df = adata.obs\n",
    "unique_days = adata.obs['day'].unique()\n",
    "unique_days = unique_days[np.isnan(unique_days) == False]\n",
    "print(\"Data shape: \", adata.shape)\n",
    "print(\"Num of unique days = {}\".format(len(unique_days)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Merge timepoints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1795931/1872061065.py:4: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['day'] = cell_tps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (236285, 19089)\n",
      "Num of unique days (merged) = 19\n",
      "Num of cell:\n",
      "[8005, 5604, 13715, 14132, 16089, 13777, 11533, 11568, 24200, 8865, 7327, 7122, 7478, 7080, 14443, 20615, 21068, 16228, 7436]\n",
      "----------------------------------------------------------------------\n",
      "Subsampling (ratio=0.1)...\n",
      "Data shape:  (23619, 19089)\n",
      "Num of unique days (sampled) = 19\n",
      "Num of cell:\n",
      "[800, 560, 1371, 1413, 1608, 1377, 1153, 1156, 2420, 886, 732, 712, 747, 708, 1444, 2061, 2106, 1622, 743]\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 70)\n",
    "print(\"Merge timepoints...\")\n",
    "cell_tps = np.floor(adata.obs['day'])\n",
    "adata.obs['day'] = cell_tps\n",
    "unique_days = adata.obs['day'].unique()\n",
    "print(\"Data shape: \", adata.shape)\n",
    "print(\"Num of unique days (merged) = {}\".format(len(unique_days)))\n",
    "print(\"Num of cell:\")\n",
    "cell_idx_per_tp = [np.where(adata.obs[\"day\"] == t)[0] for t in unique_days]\n",
    "cell_num_per_tp = [len(x) for x in cell_idx_per_tp]\n",
    "print(cell_num_per_tp)\n",
    "\n",
    "print(\"-\" * 70)\n",
    "ratio = 0.1\n",
    "print(\"Subsampling (ratio={})...\".format(ratio))\n",
    "sample_cell_idx_per_tp = [np.random.choice(x, int(len(x)*ratio), replace=False) for x in cell_idx_per_tp]\n",
    "adata = adata[np.concatenate(sample_cell_idx_per_tp), :]\n",
    "unique_days = adata.obs['day'].unique()\n",
    "print(\"Data shape: \", adata.shape)\n",
    "print(\"Num of unique days (sampled) = {}\".format(len(unique_days)))\n",
    "cell_idx_per_tp = [np.where(adata.obs[\"day\"] == t)[0] for t in unique_days]\n",
    "cell_num_per_tp = [len(x) for x in cell_idx_per_tp]\n",
    "print(\"Num of cell:\")\n",
    "print(cell_num_per_tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Data shape:  (23619, 2000)\n",
      "Num of tps:  19\n",
      "Split type: all_times\n",
      "Train tps:  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0]\n",
      "Test tps:  []\n",
      "Train data shape:  (23619, 2000)\n",
      "HVG data shape:  (23619, 2000)\n",
      "HVG meta shape:  (23619, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 70)\n",
    "split_type = \"all_times\" \n",
    "print(\"Data shape: \", adata.shape)\n",
    "print(\"Num of tps: \", len(unique_days))\n",
    "print(\"Split type: {}\".format(split_type))\n",
    "if split_type == \"three_forecasting\": \n",
    "    train_tps = unique_days[:16].tolist()\n",
    "    test_tps = unique_days[16:].tolist()\n",
    "elif split_type == \"three_interpolation\": \n",
    "    train_tps = unique_days.tolist()\n",
    "    test_tps = [train_tps[5], train_tps[10], train_tps[15]]\n",
    "    train_tps.remove(unique_days[5])\n",
    "    train_tps.remove(unique_days[10])\n",
    "    train_tps.remove(unique_days[15])\n",
    "elif split_type == \"remove_recovery\": \n",
    "    train_tps = unique_days.tolist()\n",
    "    test_idx = [5, 7, 9, 11, 15, 16, 17, 18]\n",
    "    test_tps = [train_tps[t] for t in test_idx]\n",
    "    for t in test_idx:\n",
    "        train_tps.remove(unique_days[t])\n",
    "elif split_type == \"all_times\": \n",
    "    train_tps = unique_days.tolist()\n",
    "    test_tps = []\n",
    "print(\"Train tps: \", train_tps)\n",
    "print(\"Test tps: \", test_tps)\n",
    "\n",
    "train_adata = adata[adata.obs['day'].apply(lambda x: x in train_tps)]\n",
    "print(\"Train data shape: \", train_adata.shape)\n",
    "hvgs_summary = scanpy.pp.highly_variable_genes(train_adata, n_top_genes=2000, inplace=False)\n",
    "hvgs = train_adata.var.index.values[hvgs_summary.highly_variable]\n",
    "adata = adata[:, hvgs]\n",
    "meta_df = adata.obs\n",
    "print(\"HVG data shape: \", adata.shape)\n",
    "print(\"HVG meta shape: \", meta_df.shape)\n",
    "adata.to_df().to_csv(\"reduce_processed/{}-norm_data-hvg.csv\".format(split_type)) # cell x genes\n",
    "pd.DataFrame(hvgs).to_csv(\"reduce_processed/{}-var_genes_list.csv\".format(split_type))\n",
    "meta_df.to_csv(\"reduce_processed/{}-meta_data.csv\".format(split_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
